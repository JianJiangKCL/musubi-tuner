#!/usr/bin/env python3
"""
å¯è§†åŒ–å®é™…çš„å¸§é‡‡æ ·è¿‡ç¨‹
åŸºäºpeel_it_i2v_meta_trace21.tomlé…ç½®
"""

import numpy as np
import matplotlib.pyplot as plt
import os
from typing import List, Tuple

# ä»é…ç½®æ–‡ä»¶è¯»å–çš„å‚æ•°
TARGET_FRAMES = [17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81]
FRAME_EXTRACTION = "uniform"
FRAME_SAMPLE = 2  # ä»é…ç½®ä¸­è¯»å–

def simulate_video_frames(total_frames: int = 81) -> List[int]:
    """æ¨¡æ‹Ÿä¸€ä¸ªè§†é¢‘çš„æ‰€æœ‰å¸§"""
    return list(range(1, total_frames + 1))

def uniform_sampling_simulation(video_frames: List[int], target_frame: int, frame_sample: int) -> List[List[int]]:
    """
    æ¨¡æ‹Ÿå‡åŒ€é‡‡æ ·è¿‡ç¨‹
    è¿”å›é‡‡æ ·å‡ºæ¥çš„å¸§åˆ—è¡¨
    """
    frame_count = len(video_frames)
    sampled_sequences = []

    # è®¡ç®—é‡‡æ ·ä½ç½® (ä»è®­ç»ƒä»£ç å¤åˆ¶çš„é€»è¾‘)
    frame_indices = np.linspace(0, frame_count - target_frame, frame_sample, dtype=int)

    print(f"\nğŸ¯ Target Frame: {target_frame}")
    print(f"   é‡‡æ ·ä½ç½®ç´¢å¼•: {frame_indices}")
    print(f"   å®é™…å¸§èŒƒå›´: {[f'[{i+1}:{i+target_frame}]' for i in frame_indices]}")

    for i in frame_indices:
        # è£å‰ªå‡º target_frame å¸§
        start_idx = i
        end_idx = i + target_frame
        sampled_frames = video_frames[start_idx:end_idx]
        sampled_sequences.append(sampled_frames)

        print(f"   é‡‡æ ·åºåˆ— {len(sampled_sequences)}: å¸§ {sampled_frames[0]}-{sampled_frames[-1]} ({len(sampled_frames)}å¸§)")

    return sampled_sequences

def visualize_single_target_frame(video_frames: List[int], target_frame: int, frame_sample: int):
    """å¯è§†åŒ–å•ä¸ªtarget_frameçš„é‡‡æ ·ç»“æœ"""
    fig, ax = plt.subplots(figsize=(15, 6))

    # ç»˜åˆ¶æ‰€æœ‰å¸§
    all_frames = np.arange(1, len(video_frames) + 1)
    ax.scatter(all_frames, np.ones_like(all_frames) * 2, c='lightgray', s=30, alpha=0.6, label='æœªé‡‡æ ·å¸§')

    # è®¡ç®—å¹¶ç»˜åˆ¶é‡‡æ ·åºåˆ—
    frame_indices = np.linspace(0, len(video_frames) - target_frame, frame_sample, dtype=int)

    colors = ['red', 'blue', 'green', 'orange', 'purple']
    for idx, i in enumerate(frame_indices):
        start_frame = i + 1
        end_frame = i + target_frame

        # ç»˜åˆ¶é‡‡æ ·å¸§
        sampled_frames = np.arange(start_frame, end_frame + 1)
        ax.scatter(sampled_frames, np.ones_like(sampled_frames) * 1, c=colors[idx % len(colors)],
                  s=60, marker='s', alpha=0.8, label=f'é‡‡æ ·åºåˆ— {idx+1}')

        # æ·»åŠ æ–‡æœ¬æ ‡ç­¾
        ax.text(start_frame + target_frame/2, 1.1, f'{start_frame}-{end_frame}',
               ha='center', va='bottom', fontsize=10, fontweight='bold')

    ax.set_xlim(0, len(video_frames) + 2)
    ax.set_ylim(0.5, 2.5)
    ax.set_xlabel('å¸§å·', fontsize=12)
    ax.set_title(f'å‡åŒ€é‡‡æ ·å¯è§†åŒ– - Target Frame: {target_frame}', fontsize=14, fontweight='bold')
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    ax.set_yticks([1, 2])
    ax.set_yticklabels(['é‡‡æ ·å¸§', 'å…¨éƒ¨å¸§'])

    plt.tight_layout()
    return fig

def create_comprehensive_visualization():
    """åˆ›å»ºç»¼åˆå¯è§†åŒ–"""
    print("ğŸ¬ å®é™…å¸§é‡‡æ ·è¿‡ç¨‹å¯è§†åŒ–")
    print("=" * 60)
    print(f"é…ç½®å‚æ•°:")
    print(f"  - frame_extraction: {FRAME_EXTRACTION}")
    print(f"  - frame_sample: {FRAME_SAMPLE}")
    print(f"  - target_frames: {TARGET_FRAMES}")
    print()

    # æ¨¡æ‹Ÿä¸€ä¸ª81å¸§çš„è§†é¢‘
    video_frames = simulate_video_frames(81)
    print(f"æ¨¡æ‹Ÿè§†é¢‘æ€»å¸§æ•°: {len(video_frames)}")

    # ä¸ºæ¯ä¸ªtarget_frameåˆ›å»ºå¯è§†åŒ–
    os.makedirs('/mnt/cfs/jj/musubi-tuner/sampled_bucket', exist_ok=True)

    for target_frame in TARGET_FRAMES:
        print(f"\n{'='*50}")
        print(f"å¤„ç† Target Frame: {target_frame}")

        # æ¨¡æ‹Ÿé‡‡æ ·è¿‡ç¨‹
        sampled_sequences = uniform_sampling_simulation(video_frames, target_frame, FRAME_SAMPLE)

        # åˆ›å»ºå¯è§†åŒ–
        fig = visualize_single_target_frame(video_frames, target_frame, FRAME_SAMPLE)
        output_path = f'/mnt/cfs/jj/musubi-tuner/sampled_bucket/sampling_{target_frame}frames.png'
        fig.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close(fig)

        print(f"   ğŸ“Š å¯è§†åŒ–å·²ä¿å­˜: sampling_{target_frame}frames.png")

def create_summary_table():
    """åˆ›å»ºé‡‡æ ·æ‘˜è¦è¡¨æ ¼"""
    print("\nğŸ“‹ é‡‡æ ·ç­–ç•¥æ±‡æ€»è¡¨")
    print("=" * 80)
    print("2d")
    print("-" * 80)

    video_frames = simulate_video_frames(81)

    for target_frame in TARGET_FRAMES:
        frame_indices = np.linspace(0, len(video_frames) - target_frame, FRAME_SAMPLE, dtype=int)
        sample_ranges = []
        for i in frame_indices:
            start = i + 1
            end = i + target_frame
            sample_ranges.append(f"{start}-{end}")

        ranges_str = ", ".join(sample_ranges)
        print("2d")

def main():
    """ä¸»å‡½æ•°"""
    create_comprehensive_visualization()
    create_summary_table()

    print("\n" + "=" * 80)
    print("âœ… å®é™…é‡‡æ ·å¯è§†åŒ–å®Œæˆï¼")
    print("è¾“å‡ºæ–‡ä»¶:")
    print("  - sampling_{target_frame}frames.png: å„target_frameçš„é‡‡æ ·å¯è§†åŒ–")
    print("ä½ç½®: /mnt/cfs/jj/musubi-tuner/sampled_bucket/")
    print("\nè¯´æ˜:")
    print("- æ¯ä¸ªPNGæ–‡ä»¶å±•ç¤ºäº†å¯¹åº”target_frameçš„å®é™…é‡‡æ ·ç»“æœ")
    print("- çº¢è‰²/è“è‰²æ–¹å—è¡¨ç¤ºè¢«é‡‡æ ·å‡ºæ¥çš„å¸§åºåˆ—")
    print("- ç°è‰²åœ†ç‚¹è¡¨ç¤ºè§†é¢‘ä¸­çš„å…¨éƒ¨å¸§")
    print("- æ¯ä¸ªtarget_frameä¼šç”Ÿæˆ2ä¸ªé‡‡æ ·åºåˆ—ï¼ˆframe_sample=2ï¼‰")

if __name__ == "__main__":
    main()









