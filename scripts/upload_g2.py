import oss2
import os
import uuid
import json
import requests
from io import BytesIO
import math

# åˆ›å»ºç¼“å­˜ç›®å½•
os.makedirs('results', exist_ok=True)

# åˆå§‹åŒ–ç¼“å­˜
oss_url_cache = {}
cache_file = 'results/oss_url_cache.json'
if os.path.exists(cache_file):
    try:
        with open(cache_file, 'r') as f:
            oss_url_cache = json.load(f)
    except:
        pass

internal_endpoint = os.environ.get("OSS_ENDPOINT", "oss-cn-beijing.aliyuncs.com")
access_key_id = os.environ.get("OSS_ACCESS_KEY_ID")
access_key_secret = os.environ.get("OSS_ACCESS_KEY_SECRET")
_bucket_name = os.environ.get("OSS_BUCKET_NAME", "liblibai-tmp-image")

if not access_key_id or not access_key_secret:
    raise ValueError("OSS_ACCESS_KEY_ID and OSS_ACCESS_KEY_SECRET environment variables must be set")

_auth = oss2.Auth(access_key_id=access_key_id, access_key_secret=access_key_secret)
bucket = oss2.Bucket(_auth, internal_endpoint, _bucket_name)

def upload_large_file_multipart(bucket, object_name, file_path, part_size=10*1024*1024):
    """
    ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ å¤§æ–‡ä»¶åˆ°OSS
    
    Args:
        bucket: OSS bucketå¯¹è±¡
        object_name: OSSå¯¹è±¡å
        file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
        part_size: åˆ†ç‰‡å¤§å°ï¼Œé»˜è®¤10MB
    """
    try:
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        part_count = math.ceil(file_size / part_size)
        
        print(f"æ–‡ä»¶å°†åˆ†ä¸º {part_count} ä¸ªåˆ†ç‰‡ä¸Šä¼ ï¼Œæ¯ç‰‡ {part_size/1024/1024:.1f} MB")
        
        # åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ 
        upload_id = bucket.init_multipart_upload(object_name).upload_id
        print(f"åˆ†ç‰‡ä¸Šä¼ åˆå§‹åŒ–æˆåŠŸï¼ŒUpload ID: {upload_id}")
        
        parts = []
        
        # ä¸Šä¼ æ¯ä¸ªåˆ†ç‰‡
        with open(file_path, 'rb') as f:
            for part_number in range(1, part_count + 1):
                # è¯»å–åˆ†ç‰‡æ•°æ®
                offset = (part_number - 1) * part_size
                size = min(part_size, file_size - offset)
                f.seek(offset)
                data = f.read(size)
                
                # ä¸Šä¼ åˆ†ç‰‡
                print(f"ä¸Šä¼ åˆ†ç‰‡ {part_number}/{part_count} ({size/1024/1024:.1f} MB)")
                result = bucket.upload_part(object_name, upload_id, part_number, data)
                parts.append(oss2.models.PartInfo(part_number, result.etag))
        
        # å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
        print("æ­£åœ¨åˆå¹¶åˆ†ç‰‡...")
        bucket.complete_multipart_upload(object_name, upload_id, parts)
        print("åˆ†ç‰‡ä¸Šä¼ å®Œæˆï¼")
        
    except Exception as e:
        print(f"åˆ†ç‰‡ä¸Šä¼ å¤±è´¥: {str(e)}")
        # å°è¯•å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ 
        try:
            bucket.abort_multipart_upload(object_name, upload_id)
            print("å·²å–æ¶ˆæœªå®Œæˆçš„åˆ†ç‰‡ä¸Šä¼ ")
        except:
            pass
        raise e

def check_url_validity(url, timeout=10):
    """æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆå¯è®¿é—®ï¼Œå¢å¼ºç‰ˆæœ¬èƒ½å¤„ç†æ›´å¤šè¾¹ç¼˜æƒ…å†µ"""
    # å¯¹äºå·²çŸ¥çš„OSSåŸŸåï¼Œç›´æ¥è®¤ä¸ºæœ‰æ•ˆ
    if 'liblibai-tmp-image.liblib.cloud' in url:
        return True
    
    try:
        # é¦–å…ˆå°è¯•HEADè¯·æ±‚
        response = requests.head(url, timeout=timeout, verify=False, allow_redirects=True)
        if response.status_code == 200:
            return True
    except:
        pass
    
    try:
        # å¦‚æœHEADè¯·æ±‚å¤±è´¥ï¼Œå°è¯•GETè¯·æ±‚çš„å‰å‡ ä¸ªå­—èŠ‚
        response = requests.get(url, timeout=timeout, verify=False, stream=True, headers={'Range': 'bytes=0-1023'})
        if response.status_code in [200, 206]:  # 206æ˜¯éƒ¨åˆ†å†…å®¹å“åº”
            return True
    except:
        pass
    
    try:
        # å¦‚æœRangeè¯·æ±‚ä¹Ÿå¤±è´¥ï¼Œå°è¯•å®Œæ•´GETè¯·æ±‚çš„ç¬¬ä¸€ä¸ªchunk
        # è¿™å¯¹æŸäº›æœ‰è®¿é—®æ§åˆ¶çš„URLå¯èƒ½æœ‰æ•ˆ
        response = requests.get(url, timeout=timeout, verify=False, stream=True)
        if response.status_code == 200:
            # å°è¯•è¯»å–ç¬¬ä¸€ä¸ªchunkæ¥éªŒè¯
            try:
                chunk = next(response.iter_content(chunk_size=1024))
                if chunk:
                    return True
            except:
                pass
    except:
        pass
    
    # å¯¹äºç‰¹å®šçš„åŸŸåï¼Œæˆ‘ä»¬é‡‡ç”¨æ›´å®½æ¾çš„ç­–ç•¥
    # å¦‚æœæ˜¯seedanceã€viduã€tongyiç­‰å·²çŸ¥æœåŠ¡ï¼Œå³ä½¿è®¿é—®æ£€æŸ¥å¤±è´¥ä¹Ÿå°è¯•ä¸‹è½½
    known_domains = [
        'ark-content-generation-cn-beijing.tos-cn-beijing.volces.com',  # seedance
        'prod-ss-vidu.s3.cn-northwest-1.amazonaws.com.cn',  # vidu
        'dashscope-result-wlcb-acdr-1.oss-cn-wulanchabu-acdr-1.aliyuncs.com'  # tongyi
    ]
    
    for domain in known_domains:
        if domain in url:
            print(f"âš ï¸ å·²çŸ¥åŸŸåURLè®¿é—®æ£€æŸ¥å¤±è´¥ï¼Œä½†ä»å°†å°è¯•ä¸‹è½½: {domain}")
            return True
    
    return False

def get_file_extension_from_url(url):
    """ä»URLè·å–æ–‡ä»¶æ‰©å±•å"""
    # ç§»é™¤æŸ¥è¯¢å‚æ•°
    url_path = url.split('?')[0]
    # è·å–æ‰©å±•å
    ext = os.path.splitext(url_path)[1].lower()
    if not ext:
        # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œæ ¹æ®URLå†…å®¹åˆ¤æ–­
        if 'video' in url.lower() or '.mp4' in url.lower():
            return '.mp4'
        elif 'image' in url.lower() or any(img_ext in url.lower() for img_ext in ['.jpg', '.jpeg', '.png', '.gif']):
            return '.png'
        elif 'zip' in url.lower() or '.zip' in url.lower():
            return '.zip'
    return ext or '.mp4'  # é»˜è®¤ä¸ºmp4

def upload_url(source, file_type='auto'):
    """ä¸Šä¼ æ–‡ä»¶åˆ°OSSï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–è¿œç¨‹URLï¼Œæ”¯æŒå›¾ç‰‡å’Œè§†é¢‘
    
    Args:
        source: æ–‡ä»¶è·¯å¾„æˆ–URL
        file_type: 'image', 'video', æˆ– 'auto' (è‡ªåŠ¨æ£€æµ‹)
    """
    try:
        # åˆ¤æ–­è¾“å…¥æ˜¯URLè¿˜æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
        is_url = source.startswith('http://') or source.startswith('https://')
        
        # å¦‚æœæ˜¯URLï¼Œå…ˆæ£€æŸ¥ç¼“å­˜æˆ–OSSåœ°å€
        if is_url:
            # æ£€æŸ¥URLæ˜¯å¦å·²ç»ä¸Šä¼ è¿‡
            if source in oss_url_cache:
                cached_url = oss_url_cache[source]
                print(f"ä½¿ç”¨ç¼“å­˜çš„ OSS URL: {cached_url}")
                return cached_url
                
            # å¦‚æœå·²ç»æ˜¯OSS URLï¼Œç›´æ¥è¿”å›
            if 'liblibai-tmp-image.liblib.cloud' in source:
                print(f"å·²ç»æ˜¯OSSåœ°å€ï¼Œæ— éœ€ä¸Šä¼ : {source}")
                return source
                
            # æ£€æŸ¥URLæœ‰æ•ˆæ€§
            if not check_url_validity(source):
                print(f"URLæ— æ•ˆæˆ–å·²è¿‡æœŸ: {source}")
                return None
                
            # ä¸‹è½½è¿œç¨‹æ–‡ä»¶åˆ°æœ¬åœ°
            temp_dir = os.path.join(os.getcwd(), 'static', 'temp')
            os.makedirs(temp_dir, exist_ok=True)
            
            # æ ¹æ®URLç¡®å®šæ–‡ä»¶æ‰©å±•å
            file_ext = get_file_extension_from_url(source)
            if file_type == 'auto':
                # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹
                if file_ext in ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm']:
                    file_type = 'video'
                elif file_ext in ['.zip', '.rar', '.7z', '.tar', '.gz']:
                    file_type = 'zip'
                else:
                    file_type = 'image'
            
            file_name = f"{uuid.uuid4()}{file_ext}"
            local_path = os.path.join(temp_dir, file_name)
            
            print(f"ä¸‹è½½è¿œç¨‹{file_type}æ–‡ä»¶: {source}")
            try:
                response = requests.get(source, timeout=60, verify=False, stream=True)
                if response.status_code != 200:
                    print(f"ä¸‹è½½è¿œç¨‹æ–‡ä»¶å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return None
                    
                # æµå¼ä¸‹è½½ï¼Œé€‚åˆå¤§æ–‡ä»¶
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                print(f"æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°: {local_path}")
                
                # æ›´æ–°sourceä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œç»§ç»­å¤„ç†
                source = local_path
            except Exception as download_error:
                print(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {download_error}")
                return None
        
        # å¤„ç†æœ¬åœ°æ–‡ä»¶
        if not is_url or os.path.exists(source):
            # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶ç¼“å­˜
            if source in oss_url_cache and os.path.exists(source):
                cached_url = oss_url_cache[source]
                print(f"ä½¿ç”¨ç¼“å­˜çš„ OSS URL: {cached_url}")
                return cached_url
            
            # ç¡®å®šæ–‡ä»¶ç±»å‹
            if file_type == 'auto':
                file_ext = os.path.splitext(source)[1].lower()
                if file_ext in ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm']:
                    file_type = 'video'
                elif file_ext in ['.zip', '.rar', '.7z', '.tar', '.gz']:
                    file_type = 'zip'
                else:
                    file_type = 'image'
            
            # ç”ŸæˆOSSå¯¹è±¡å
            if file_type == 'video':
                object_name = f"sd-videos/{str(uuid.uuid4())}.mp4"
            elif file_type == 'zip':
                original_ext = os.path.splitext(source)[1].lower()
                object_name = f"training-data/{str(uuid.uuid4())}{original_ext}"
            else:
                object_name = f"sd-images/{str(uuid.uuid4())}.png"
                
            # ä¸Šä¼ æ–‡ä»¶åˆ°OSS
            print(f"å¼€å§‹ä¸Šä¼ {file_type}æ–‡ä»¶åˆ°OSS: {source}")
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(source)
            print(f"æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.1f} MB")
            
            # å¯¹äºå¤§æ–‡ä»¶ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ ï¼Œå°æ–‡ä»¶ä½¿ç”¨ç®€å•ä¸Šä¼ 
            if file_size > 100 * 1024 * 1024:  # å¤§äº100MBä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 
                print("ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ ...")
                upload_large_file_multipart(bucket, object_name, source)
            else:
                print("ä½¿ç”¨ç®€å•ä¸Šä¼ ...")
                bucket.put_object_from_file(object_name, source)
            
            print(f"ä¸Šä¼ æ–‡ä»¶ {source} åˆ°OSSæˆåŠŸ")
            
            # å®Œæ•´çš„ URL
            full_url = 'https://liblibai-tmp-image.liblib.cloud/' + object_name
            print(f"{file_type}æ–‡ä»¶OSSåœ°å€ï¼š{full_url}")
            
            # è®°å½•åˆ°ç¼“å­˜
            original_source = source
            if is_url:
                # è·å–åŸå§‹URLï¼ˆä¸‹è½½å‰çš„URLï¼‰
                for key, value in locals().items():
                    if key == 'source' and isinstance(value, str) and value.startswith('http'):
                        original_source = value
                        break
            
            oss_url_cache[original_source] = full_url
            oss_url_cache[source] = full_url  # åŒæ—¶ç¼“å­˜æœ¬åœ°è·¯å¾„
            
            # ä¿å­˜ç¼“å­˜
            with open('results/oss_url_cache.json', 'w') as f:
                json.dump(oss_url_cache, f, indent=2)
            
            # å¦‚æœæ˜¯ä¸´æ—¶ä¸‹è½½çš„æ–‡ä»¶ï¼Œæ¸…ç†å®ƒ
            if is_url and os.path.exists(source) and 'temp' in source:
                try:
                    os.remove(source)
                    print(f"ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤: {source}")
                except Exception as e:
                    print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            
            return full_url
        else:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {source}")
            return None
            
    except Exception as e:
        print(f"ä¸Šä¼ è¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def upload_video_url(video_url):
    """ä¸“é—¨ç”¨äºä¸Šä¼ è§†é¢‘URLçš„ä¾¿æ·å‡½æ•°"""
    return upload_url(video_url, file_type='video')

def upload_image_url(image_url):
    """ä¸“é—¨ç”¨äºä¸Šä¼ å›¾ç‰‡URLçš„ä¾¿æ·å‡½æ•°"""
    return upload_url(image_url, file_type='image')

def upload_zip_file(zip_path):
    """ä¸“é—¨ç”¨äºä¸Šä¼ zipæ–‡ä»¶çš„ä¾¿æ·å‡½æ•°"""
    return upload_url(zip_path, file_type='zip')

def upload_model_file(model_file_path, model_dir_uuid=None):
    """
    ä¸“é—¨ç”¨äºä¸Šä¼ æ¨¡å‹æ–‡ä»¶çš„å‡½æ•°
    
    Args:
        model_file_path: æ¨¡å‹æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„
        model_dir_uuid: æ¨¡å‹ç›®å½•UUIDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆã€‚
                       åŒä¸€ä¸ªæ•°æ®é›†çš„å¤šä¸ªæ¨¡å‹æ–‡ä»¶åº”ä½¿ç”¨ç›¸åŒçš„model_dir_uuid
    
    Returns:
        tuple: (oss_url, model_dir_uuid) è¿”å›OSSåœ°å€å’Œæ¨¡å‹ç›®å½•UUID
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_file_path):
            print(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file_path}")
            return None, None
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        file_ext = os.path.splitext(model_file_path)[1].lower()
        supported_extensions = ['.safetensors', '.ckpt', '.pt', '.bin', '.pth', '.gguf', '.sft']
        
        if file_ext not in supported_extensions:
            print(f"ä¸æ”¯æŒçš„æ¨¡å‹æ–‡ä»¶æ ¼å¼: {file_ext}")
            print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(supported_extensions)}")
            return None, None
        
        # ç”ŸæˆUUIDï¼ˆå»æ‰è¿å­—ç¬¦ï¼‰
        if model_dir_uuid is None:
            model_dir_uuid = str(uuid.uuid4()).replace("-", "")
            print(f"ç”Ÿæˆæ–°çš„æ¨¡å‹ç›®å½•UUID: {model_dir_uuid}")
        else:
            print(f"ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹ç›®å½•UUID: {model_dir_uuid}")
        
        model_file_uuid = str(uuid.uuid4()).replace("-", "")
        print(f"æ¨¡å‹æ–‡ä»¶UUID: {model_file_uuid}")
        
        # ç”ŸæˆOSSå¯¹è±¡å
        object_name = f"models/chaowei/{model_dir_uuid}/{model_file_uuid}{file_ext}"
        print(f"OSSå¯¹è±¡å: {object_name}")
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(model_file_path)
        print(f"æ¨¡å‹æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.1f} MB")
        
        # å¼€å§‹ä¸Šä¼ 
        print(f"å¼€å§‹ä¸Šä¼ æ¨¡å‹æ–‡ä»¶åˆ°OSS: {model_file_path}")
        
        # å¯¹äºå¤§æ–‡ä»¶ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ ï¼Œå°æ–‡ä»¶ä½¿ç”¨ç®€å•ä¸Šä¼ 
        if file_size > 100 * 1024 * 1024:  # å¤§äº100MBä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 
            print("ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ ...")
            upload_large_file_multipart(bucket, object_name, model_file_path)
        else:
            print("ä½¿ç”¨ç®€å•ä¸Šä¼ ...")
            bucket.put_object_from_file(object_name, model_file_path)
        
        print(f"æ¨¡å‹æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {model_file_path}")
        
        # ç”Ÿæˆå®Œæ•´çš„URLï¼ˆä½¿ç”¨liblib.cloudåŸŸåï¼‰
        full_url = 'https://liblibai-tmp-image.liblib.cloud/' + object_name
        print(f"æ¨¡å‹æ–‡ä»¶OSSåœ°å€: {full_url}")
        
        return full_url, model_dir_uuid
        
    except Exception as e:
        print(f"ä¸Šä¼ æ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None

def upload_model_files_batch(model_file_paths, model_dir_uuid=None):
    """
    æ‰¹é‡ä¸Šä¼ åŒä¸€ä¸ªæ•°æ®é›†çš„å¤šä¸ªæ¨¡å‹æ–‡ä»¶
    
    Args:
        model_file_paths: æ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        model_dir_uuid: æ¨¡å‹ç›®å½•UUIDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆã€‚
                       åŒä¸€æ‰¹æ¬¡çš„æ‰€æœ‰æ–‡ä»¶ä½¿ç”¨ç›¸åŒçš„model_dir_uuid
    
    Returns:
        tuple: (upload_results, model_dir_uuid)
               upload_results: [{'file_path': str, 'oss_url': str, 'success': bool}, ...]
               model_dir_uuid: ä½¿ç”¨çš„æ¨¡å‹ç›®å½•UUID
    """
    upload_results = []
    
    if not model_file_paths:
        print("æ²¡æœ‰æä¾›æ¨¡å‹æ–‡ä»¶è·¯å¾„")
        return upload_results, None
    
    # å¦‚æœæ²¡æœ‰æä¾›model_dir_uuidï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„
    if model_dir_uuid is None:
        model_dir_uuid = str(uuid.uuid4()).replace("-", "")
        print(f"ä¸ºæ‰¹é‡ä¸Šä¼ ç”Ÿæˆæ¨¡å‹ç›®å½•UUID: {model_dir_uuid}")
    
    print(f"å¼€å§‹æ‰¹é‡ä¸Šä¼  {len(model_file_paths)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    print("-" * 60)
    
    for i, file_path in enumerate(model_file_paths, 1):
        print(f"\n[{i}/{len(model_file_paths)}] ä¸Šä¼ æ¨¡å‹æ–‡ä»¶: {os.path.basename(file_path)}")
        
        oss_url, _ = upload_model_file(file_path, model_dir_uuid)
        
        result = {
            'file_path': file_path,
            'oss_url': oss_url,
            'success': oss_url is not None
        }
        upload_results.append(result)
        
        if result['success']:
            print(f"âœ… ä¸Šä¼ æˆåŠŸ: {os.path.basename(file_path)}")
        else:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {os.path.basename(file_path)}")
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in upload_results if r['success'])
    print(f"\nğŸ“Š æ‰¹é‡ä¸Šä¼ å®Œæˆ:")
    print(f"   æ€»æ–‡ä»¶æ•°: {len(model_file_paths)}")
    print(f"   æˆåŠŸä¸Šä¼ : {success_count}")
    print(f"   ä¸Šä¼ å¤±è´¥: {len(model_file_paths) - success_count}")
    print(f"   æ¨¡å‹ç›®å½•UUID: {model_dir_uuid}")
    
    return upload_results, model_dir_uuid

def migrate_history_images(history_data):
    """å°†å†å²ä»»åŠ¡ä¸­çš„å›¾ç‰‡ä¸Šä¼ åˆ°OSS"""
    if not history_data:
        return history_data
        
    print(f"å¼€å§‹è¿ç§»{len(history_data)}æ¡å†å²è®°å½•çš„å›¾ç‰‡")
    updated = False
    
    for task in history_data:
        # å¤„ç†resultImageUrl
        if task.get('resultImageUrl') and not task.get('resultImageUrl').startswith('https://liblibai-tmp-image.liblib.cloud/'):
            oss_url = upload_url(task['resultImageUrl'])
            if oss_url != task['resultImageUrl']:
                task['resultImageUrl'] = oss_url
                updated = True
                print(f"è¿ç§»ç»“æœå›¾ç‰‡: {oss_url}")
        
        # å¤„ç†imageUrlsæ•°ç»„
        if task.get('imageUrls') and isinstance(task['imageUrls'], list):
            for i, img_url in enumerate(task['imageUrls']):
                if img_url and not img_url.startswith('https://liblibai-tmp-image.liblib.cloud/'):
                    oss_url = upload_url(img_url)
                    if oss_url != img_url:
                        task['imageUrls'][i] = oss_url
                        updated = True
                        print(f"è¿ç§»ä¸Šä¼ å›¾ç‰‡: {oss_url}")
    
    print(f"å†å²è®°å½•å›¾ç‰‡è¿ç§»å®Œæˆï¼Œ{'æœ‰' if updated else 'æ— '}æ›´æ–°")
    return history_data, updated
